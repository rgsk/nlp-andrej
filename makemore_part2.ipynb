{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s: i+1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i: s for s,i in stoi.items()}\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... ---> e\n",
      "..e ---> m\n",
      ".em ---> m\n",
      "emm ---> a\n",
      "mma ---> .\n",
      "olivia\n",
      "... ---> o\n",
      "..o ---> l\n",
      ".ol ---> i\n",
      "oli ---> v\n",
      "liv ---> i\n",
      "ivi ---> a\n",
      "via ---> .\n",
      "ava\n",
      "... ---> a\n",
      "..a ---> v\n",
      ".av ---> a\n",
      "ava ---> .\n",
      "isabella\n",
      "... ---> i\n",
      "..i ---> s\n",
      ".is ---> a\n",
      "isa ---> b\n",
      "sab ---> e\n",
      "abe ---> l\n",
      "bel ---> l\n",
      "ell ---> a\n",
      "lla ---> .\n",
      "sophia\n",
      "... ---> s\n",
      "..s ---> o\n",
      ".so ---> p\n",
      "sop ---> h\n",
      "oph ---> i\n",
      "phi ---> a\n",
      "hia ---> .\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "X, Y = [], []\n",
    "for w in words[:5]:\n",
    "    print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "        context = context[1:] + [ix]\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0],\n",
       "        [ 0,  0,  5],\n",
       "        [ 0,  5, 13],\n",
       "        [ 5, 13, 13],\n",
       "        [13, 13,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 15],\n",
       "        [ 0, 15, 12],\n",
       "        [15, 12,  9],\n",
       "        [12,  9, 22],\n",
       "        [ 9, 22,  9],\n",
       "        [22,  9,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  1],\n",
       "        [ 0,  1, 22],\n",
       "        [ 1, 22,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  9],\n",
       "        [ 0,  9, 19],\n",
       "        [ 9, 19,  1],\n",
       "        [19,  1,  2],\n",
       "        [ 1,  2,  5],\n",
       "        [ 2,  5, 12],\n",
       "        [ 5, 12, 12],\n",
       "        [12, 12,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 19],\n",
       "        [ 0, 19, 15],\n",
       "        [19, 15, 16],\n",
       "        [15, 16,  8],\n",
       "        [16,  8,  9],\n",
       "        [ 8,  9,  1]])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
       "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1232,  0.5990],\n",
       "        [ 0.1396,  1.8691],\n",
       "        [-0.7492,  1.1291],\n",
       "        [ 1.6471,  0.2546],\n",
       "        [ 0.4301, -1.7655],\n",
       "        [-0.8806, -0.1010],\n",
       "        [ 1.8179,  1.5176],\n",
       "        [-1.2494, -0.5209],\n",
       "        [-0.0534,  1.0390],\n",
       "        [-0.2567, -0.0047],\n",
       "        [ 0.0551, -0.3240],\n",
       "        [ 2.2759, -0.9436],\n",
       "        [-0.7089, -0.2337],\n",
       "        [-1.0022,  0.9037],\n",
       "        [-0.0350, -1.1494],\n",
       "        [-1.9505, -0.4709],\n",
       "        [ 0.2653, -1.4764],\n",
       "        [ 0.4577,  0.5937],\n",
       "        [ 1.7221,  1.2049],\n",
       "        [-0.6718,  1.0432],\n",
       "        [-0.5086,  0.2634],\n",
       "        [ 2.3453, -0.6539],\n",
       "        [ 0.5631,  1.7680],\n",
       "        [-0.7234,  2.4806],\n",
       "        [ 1.4669,  1.7232],\n",
       "        [ 1.1773,  0.1628],\n",
       "        [-2.2183, -0.8590]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = torch.randn([27, 2])\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.8806, -0.1010])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(torch.tensor(5), num_classes=27).float() @ C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.8806, -0.1010])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8806, -0.1010],\n",
       "        [ 1.8179,  1.5176],\n",
       "        [-1.2494, -0.5209]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[[5, 6, 7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8806, -0.1010],\n",
       "        [ 1.8179,  1.5176],\n",
       "        [-1.2494, -0.5209],\n",
       "        [-1.2494, -0.5209]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[torch.tensor([5, 6, 7, 7])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1232,  0.5990],\n",
       "         [-1.1232,  0.5990],\n",
       "         [-1.1232,  0.5990]],\n",
       "\n",
       "        [[-1.1232,  0.5990],\n",
       "         [-1.1232,  0.5990],\n",
       "         [-0.8806, -0.1010]],\n",
       "\n",
       "        [[-1.1232,  0.5990],\n",
       "         [-0.8806, -0.1010],\n",
       "         [-1.0022,  0.9037]],\n",
       "\n",
       "        [[-0.8806, -0.1010],\n",
       "         [-1.0022,  0.9037],\n",
       "         [-1.0022,  0.9037]],\n",
       "\n",
       "        [[-1.0022,  0.9037],\n",
       "         [-1.0022,  0.9037],\n",
       "         [ 0.1396,  1.8691]],\n",
       "\n",
       "        [[-1.1232,  0.5990],\n",
       "         [-1.1232,  0.5990],\n",
       "         [-1.1232,  0.5990]],\n",
       "\n",
       "        [[-1.1232,  0.5990],\n",
       "         [-1.1232,  0.5990],\n",
       "         [-1.9505, -0.4709]],\n",
       "\n",
       "        [[-1.1232,  0.5990],\n",
       "         [-1.9505, -0.4709],\n",
       "         [-0.7089, -0.2337]],\n",
       "\n",
       "        [[-1.9505, -0.4709],\n",
       "         [-0.7089, -0.2337],\n",
       "         [-0.2567, -0.0047]],\n",
       "\n",
       "        [[-0.7089, -0.2337],\n",
       "         [-0.2567, -0.0047],\n",
       "         [ 0.5631,  1.7680]],\n",
       "\n",
       "        [[-0.2567, -0.0047],\n",
       "         [ 0.5631,  1.7680],\n",
       "         [-0.2567, -0.0047]],\n",
       "\n",
       "        [[ 0.5631,  1.7680],\n",
       "         [-0.2567, -0.0047],\n",
       "         [ 0.1396,  1.8691]],\n",
       "\n",
       "        [[-1.1232,  0.5990],\n",
       "         [-1.1232,  0.5990],\n",
       "         [-1.1232,  0.5990]],\n",
       "\n",
       "        [[-1.1232,  0.5990],\n",
       "         [-1.1232,  0.5990],\n",
       "         [ 0.1396,  1.8691]],\n",
       "\n",
       "        [[-1.1232,  0.5990],\n",
       "         [ 0.1396,  1.8691],\n",
       "         [ 0.5631,  1.7680]],\n",
       "\n",
       "        [[ 0.1396,  1.8691],\n",
       "         [ 0.5631,  1.7680],\n",
       "         [ 0.1396,  1.8691]],\n",
       "\n",
       "        [[-1.1232,  0.5990],\n",
       "         [-1.1232,  0.5990],\n",
       "         [-1.1232,  0.5990]],\n",
       "\n",
       "        [[-1.1232,  0.5990],\n",
       "         [-1.1232,  0.5990],\n",
       "         [-0.2567, -0.0047]],\n",
       "\n",
       "        [[-1.1232,  0.5990],\n",
       "         [-0.2567, -0.0047],\n",
       "         [-0.6718,  1.0432]],\n",
       "\n",
       "        [[-0.2567, -0.0047],\n",
       "         [-0.6718,  1.0432],\n",
       "         [ 0.1396,  1.8691]],\n",
       "\n",
       "        [[-0.6718,  1.0432],\n",
       "         [ 0.1396,  1.8691],\n",
       "         [-0.7492,  1.1291]],\n",
       "\n",
       "        [[ 0.1396,  1.8691],\n",
       "         [-0.7492,  1.1291],\n",
       "         [-0.8806, -0.1010]],\n",
       "\n",
       "        [[-0.7492,  1.1291],\n",
       "         [-0.8806, -0.1010],\n",
       "         [-0.7089, -0.2337]],\n",
       "\n",
       "        [[-0.8806, -0.1010],\n",
       "         [-0.7089, -0.2337],\n",
       "         [-0.7089, -0.2337]],\n",
       "\n",
       "        [[-0.7089, -0.2337],\n",
       "         [-0.7089, -0.2337],\n",
       "         [ 0.1396,  1.8691]],\n",
       "\n",
       "        [[-1.1232,  0.5990],\n",
       "         [-1.1232,  0.5990],\n",
       "         [-1.1232,  0.5990]],\n",
       "\n",
       "        [[-1.1232,  0.5990],\n",
       "         [-1.1232,  0.5990],\n",
       "         [-0.6718,  1.0432]],\n",
       "\n",
       "        [[-1.1232,  0.5990],\n",
       "         [-0.6718,  1.0432],\n",
       "         [-1.9505, -0.4709]],\n",
       "\n",
       "        [[-0.6718,  1.0432],\n",
       "         [-1.9505, -0.4709],\n",
       "         [ 0.2653, -1.4764]],\n",
       "\n",
       "        [[-1.9505, -0.4709],\n",
       "         [ 0.2653, -1.4764],\n",
       "         [-0.0534,  1.0390]],\n",
       "\n",
       "        [[ 0.2653, -1.4764],\n",
       "         [-0.0534,  1.0390],\n",
       "         [-0.2567, -0.0047]],\n",
       "\n",
       "        [[-0.0534,  1.0390],\n",
       "         [-0.2567, -0.0047],\n",
       "         [ 0.1396,  1.8691]]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[X].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X]\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1232,  0.5990, -1.1232,  0.5990, -1.1232,  0.5990],\n",
       "        [-1.1232,  0.5990, -1.1232,  0.5990, -0.8806, -0.1010],\n",
       "        [-1.1232,  0.5990, -0.8806, -0.1010, -1.0022,  0.9037],\n",
       "        [-0.8806, -0.1010, -1.0022,  0.9037, -1.0022,  0.9037],\n",
       "        [-1.0022,  0.9037, -1.0022,  0.9037,  0.1396,  1.8691],\n",
       "        [-1.1232,  0.5990, -1.1232,  0.5990, -1.1232,  0.5990],\n",
       "        [-1.1232,  0.5990, -1.1232,  0.5990, -1.9505, -0.4709],\n",
       "        [-1.1232,  0.5990, -1.9505, -0.4709, -0.7089, -0.2337],\n",
       "        [-1.9505, -0.4709, -0.7089, -0.2337, -0.2567, -0.0047],\n",
       "        [-0.7089, -0.2337, -0.2567, -0.0047,  0.5631,  1.7680],\n",
       "        [-0.2567, -0.0047,  0.5631,  1.7680, -0.2567, -0.0047],\n",
       "        [ 0.5631,  1.7680, -0.2567, -0.0047,  0.1396,  1.8691],\n",
       "        [-1.1232,  0.5990, -1.1232,  0.5990, -1.1232,  0.5990],\n",
       "        [-1.1232,  0.5990, -1.1232,  0.5990,  0.1396,  1.8691],\n",
       "        [-1.1232,  0.5990,  0.1396,  1.8691,  0.5631,  1.7680],\n",
       "        [ 0.1396,  1.8691,  0.5631,  1.7680,  0.1396,  1.8691],\n",
       "        [-1.1232,  0.5990, -1.1232,  0.5990, -1.1232,  0.5990],\n",
       "        [-1.1232,  0.5990, -1.1232,  0.5990, -0.2567, -0.0047],\n",
       "        [-1.1232,  0.5990, -0.2567, -0.0047, -0.6718,  1.0432],\n",
       "        [-0.2567, -0.0047, -0.6718,  1.0432,  0.1396,  1.8691],\n",
       "        [-0.6718,  1.0432,  0.1396,  1.8691, -0.7492,  1.1291],\n",
       "        [ 0.1396,  1.8691, -0.7492,  1.1291, -0.8806, -0.1010],\n",
       "        [-0.7492,  1.1291, -0.8806, -0.1010, -0.7089, -0.2337],\n",
       "        [-0.8806, -0.1010, -0.7089, -0.2337, -0.7089, -0.2337],\n",
       "        [-0.7089, -0.2337, -0.7089, -0.2337,  0.1396,  1.8691],\n",
       "        [-1.1232,  0.5990, -1.1232,  0.5990, -1.1232,  0.5990],\n",
       "        [-1.1232,  0.5990, -1.1232,  0.5990, -0.6718,  1.0432],\n",
       "        [-1.1232,  0.5990, -0.6718,  1.0432, -1.9505, -0.4709],\n",
       "        [-0.6718,  1.0432, -1.9505, -0.4709,  0.2653, -1.4764],\n",
       "        [-1.9505, -0.4709,  0.2653, -1.4764, -0.0534,  1.0390],\n",
       "        [ 0.2653, -1.4764, -0.0534,  1.0390, -0.2567, -0.0047],\n",
       "        [-0.0534,  1.0390, -0.2567, -0.0047,  0.1396,  1.8691]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([emb[:, 0, :], emb[:, 1, :], emb[:, 2, :]], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1232,  0.5990, -1.1232,  0.5990, -1.1232,  0.5990],\n",
       "        [-1.1232,  0.5990, -1.1232,  0.5990, -0.8806, -0.1010],\n",
       "        [-1.1232,  0.5990, -0.8806, -0.1010, -1.0022,  0.9037],\n",
       "        [-0.8806, -0.1010, -1.0022,  0.9037, -1.0022,  0.9037],\n",
       "        [-1.0022,  0.9037, -1.0022,  0.9037,  0.1396,  1.8691],\n",
       "        [-1.1232,  0.5990, -1.1232,  0.5990, -1.1232,  0.5990],\n",
       "        [-1.1232,  0.5990, -1.1232,  0.5990, -1.9505, -0.4709],\n",
       "        [-1.1232,  0.5990, -1.9505, -0.4709, -0.7089, -0.2337],\n",
       "        [-1.9505, -0.4709, -0.7089, -0.2337, -0.2567, -0.0047],\n",
       "        [-0.7089, -0.2337, -0.2567, -0.0047,  0.5631,  1.7680],\n",
       "        [-0.2567, -0.0047,  0.5631,  1.7680, -0.2567, -0.0047],\n",
       "        [ 0.5631,  1.7680, -0.2567, -0.0047,  0.1396,  1.8691],\n",
       "        [-1.1232,  0.5990, -1.1232,  0.5990, -1.1232,  0.5990],\n",
       "        [-1.1232,  0.5990, -1.1232,  0.5990,  0.1396,  1.8691],\n",
       "        [-1.1232,  0.5990,  0.1396,  1.8691,  0.5631,  1.7680],\n",
       "        [ 0.1396,  1.8691,  0.5631,  1.7680,  0.1396,  1.8691],\n",
       "        [-1.1232,  0.5990, -1.1232,  0.5990, -1.1232,  0.5990],\n",
       "        [-1.1232,  0.5990, -1.1232,  0.5990, -0.2567, -0.0047],\n",
       "        [-1.1232,  0.5990, -0.2567, -0.0047, -0.6718,  1.0432],\n",
       "        [-0.2567, -0.0047, -0.6718,  1.0432,  0.1396,  1.8691],\n",
       "        [-0.6718,  1.0432,  0.1396,  1.8691, -0.7492,  1.1291],\n",
       "        [ 0.1396,  1.8691, -0.7492,  1.1291, -0.8806, -0.1010],\n",
       "        [-0.7492,  1.1291, -0.8806, -0.1010, -0.7089, -0.2337],\n",
       "        [-0.8806, -0.1010, -0.7089, -0.2337, -0.7089, -0.2337],\n",
       "        [-0.7089, -0.2337, -0.7089, -0.2337,  0.1396,  1.8691],\n",
       "        [-1.1232,  0.5990, -1.1232,  0.5990, -1.1232,  0.5990],\n",
       "        [-1.1232,  0.5990, -1.1232,  0.5990, -0.6718,  1.0432],\n",
       "        [-1.1232,  0.5990, -0.6718,  1.0432, -1.9505, -0.4709],\n",
       "        [-0.6718,  1.0432, -1.9505, -0.4709,  0.2653, -1.4764],\n",
       "        [-1.9505, -0.4709,  0.2653, -1.4764, -0.0534,  1.0390],\n",
       "        [ 0.2653, -1.4764, -0.0534,  1.0390, -0.2567, -0.0047],\n",
       "        [-0.0534,  1.0390, -0.2567, -0.0047,  0.1396,  1.8691]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(torch.unbind(emb, 1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1232,  0.5990, -1.1232,  0.5990, -1.1232,  0.5990],\n",
       "        [-1.1232,  0.5990, -1.1232,  0.5990, -0.8806, -0.1010],\n",
       "        [-1.1232,  0.5990, -0.8806, -0.1010, -1.0022,  0.9037],\n",
       "        [-0.8806, -0.1010, -1.0022,  0.9037, -1.0022,  0.9037],\n",
       "        [-1.0022,  0.9037, -1.0022,  0.9037,  0.1396,  1.8691],\n",
       "        [-1.1232,  0.5990, -1.1232,  0.5990, -1.1232,  0.5990],\n",
       "        [-1.1232,  0.5990, -1.1232,  0.5990, -1.9505, -0.4709],\n",
       "        [-1.1232,  0.5990, -1.9505, -0.4709, -0.7089, -0.2337],\n",
       "        [-1.9505, -0.4709, -0.7089, -0.2337, -0.2567, -0.0047],\n",
       "        [-0.7089, -0.2337, -0.2567, -0.0047,  0.5631,  1.7680],\n",
       "        [-0.2567, -0.0047,  0.5631,  1.7680, -0.2567, -0.0047],\n",
       "        [ 0.5631,  1.7680, -0.2567, -0.0047,  0.1396,  1.8691],\n",
       "        [-1.1232,  0.5990, -1.1232,  0.5990, -1.1232,  0.5990],\n",
       "        [-1.1232,  0.5990, -1.1232,  0.5990,  0.1396,  1.8691],\n",
       "        [-1.1232,  0.5990,  0.1396,  1.8691,  0.5631,  1.7680],\n",
       "        [ 0.1396,  1.8691,  0.5631,  1.7680,  0.1396,  1.8691],\n",
       "        [-1.1232,  0.5990, -1.1232,  0.5990, -1.1232,  0.5990],\n",
       "        [-1.1232,  0.5990, -1.1232,  0.5990, -0.2567, -0.0047],\n",
       "        [-1.1232,  0.5990, -0.2567, -0.0047, -0.6718,  1.0432],\n",
       "        [-0.2567, -0.0047, -0.6718,  1.0432,  0.1396,  1.8691],\n",
       "        [-0.6718,  1.0432,  0.1396,  1.8691, -0.7492,  1.1291],\n",
       "        [ 0.1396,  1.8691, -0.7492,  1.1291, -0.8806, -0.1010],\n",
       "        [-0.7492,  1.1291, -0.8806, -0.1010, -0.7089, -0.2337],\n",
       "        [-0.8806, -0.1010, -0.7089, -0.2337, -0.7089, -0.2337],\n",
       "        [-0.7089, -0.2337, -0.7089, -0.2337,  0.1396,  1.8691],\n",
       "        [-1.1232,  0.5990, -1.1232,  0.5990, -1.1232,  0.5990],\n",
       "        [-1.1232,  0.5990, -1.1232,  0.5990, -0.6718,  1.0432],\n",
       "        [-1.1232,  0.5990, -0.6718,  1.0432, -1.9505, -0.4709],\n",
       "        [-0.6718,  1.0432, -1.9505, -0.4709,  0.2653, -1.4764],\n",
       "        [-1.9505, -0.4709,  0.2653, -1.4764, -0.0534,  1.0390],\n",
       "        [ 0.2653, -1.4764, -0.0534,  1.0390, -0.2567, -0.0047],\n",
       "        [-0.0534,  1.0390, -0.2567, -0.0047,  0.1396,  1.8691]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.view(32, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.randn((6, 100))\n",
    "b1 = torch.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4022, -0.7067, -0.7679,  ...,  0.9510,  0.9940, -0.1875],\n",
       "        [-0.9140, -0.9431, -0.8712,  ...,  0.9637,  0.9867, -0.0159],\n",
       "        [-0.4428, -0.4182, -0.6355,  ...,  0.9807,  0.9928,  0.2494],\n",
       "        ...,\n",
       "        [-0.7353,  0.9663, -0.8908,  ...,  0.0693,  0.9973, -0.7554],\n",
       "        [ 0.9067,  0.8773, -0.7843,  ..., -0.9963,  0.9938, -0.9359],\n",
       "        [ 0.9514,  0.4171,  0.5301,  ...,  0.9999,  0.9219,  0.9407]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = torch.randn((100, 27))\n",
    "b2 = torch.randn(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = h @ W2 + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = logits.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = counts / counts.sum(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(18.5443)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-probs[torch.arange(32), Y].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- now made respectable :) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emma\n",
      "... ---> e\n",
      "..e ---> m\n",
      ".em ---> m\n",
      "emm ---> a\n",
      "mma ---> .\n",
      "olivia\n",
      "... ---> o\n",
      "..o ---> l\n",
      ".ol ---> i\n",
      "oli ---> v\n",
      "liv ---> i\n",
      "ivi ---> a\n",
      "via ---> .\n",
      "ava\n",
      "... ---> a\n",
      "..a ---> v\n",
      ".av ---> a\n",
      "ava ---> .\n",
      "isabella\n",
      "... ---> i\n",
      "..i ---> s\n",
      ".is ---> a\n",
      "isa ---> b\n",
      "sab ---> e\n",
      "abe ---> l\n",
      "bel ---> l\n",
      "ell ---> a\n",
      "lla ---> .\n",
      "sophia\n",
      "... ---> s\n",
      "..s ---> o\n",
      ".so ---> p\n",
      "sop ---> h\n",
      "oph ---> i\n",
      "phi ---> a\n",
      "hia ---> .\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "X, Y = [], []\n",
    "for w in words[:5]:\n",
    "    print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "        context = context[1:] + [ix]\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.Size([32]))"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn(27, 2, generator=g)\n",
    "W1 = torch.randn((6, 100), generator=g)\n",
    "b1 = torch.randn(100, generator=g)\n",
    "W2 = torch.randn((100, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters) # number of parameters in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.76971435546875\n",
      "13.656402587890625\n",
      "11.298770904541016\n",
      "9.452458381652832\n",
      "7.984263896942139\n",
      "6.891323089599609\n",
      "6.100015640258789\n",
      "5.452036380767822\n",
      "4.8981523513793945\n",
      "4.414664268493652\n",
      "3.9858498573303223\n",
      "3.6028308868408203\n",
      "3.2621421813964844\n",
      "2.96138072013855\n",
      "2.6982970237731934\n",
      "2.469712734222412\n",
      "2.271660566329956\n",
      "2.1012842655181885\n",
      "1.957176923751831\n",
      "1.8374860286712646\n",
      "1.7380965948104858\n",
      "1.6535117626190186\n",
      "1.5790901184082031\n",
      "1.5117673873901367\n",
      "1.449605107307434\n",
      "1.3913123607635498\n",
      "1.3359928131103516\n",
      "1.2830535173416138\n",
      "1.232191801071167\n",
      "1.1833821535110474\n",
      "1.1367993354797363\n",
      "1.092665195465088\n",
      "1.0510929822921753\n",
      "1.012027621269226\n",
      "0.9752710461616516\n",
      "0.9405569434165955\n",
      "0.9076131582260132\n",
      "0.8761925101280212\n",
      "0.8460896015167236\n",
      "0.8171363472938538\n",
      "0.7891995310783386\n",
      "0.7621749639511108\n",
      "0.7359815835952759\n",
      "0.710558295249939\n",
      "0.6858615279197693\n",
      "0.6618656516075134\n",
      "0.6385658979415894\n",
      "0.6159821152687073\n",
      "0.5941662192344666\n",
      "0.5732107162475586\n",
      "0.553256630897522\n",
      "0.5344885587692261\n",
      "0.5171172618865967\n",
      "0.5013318061828613\n",
      "0.4872432053089142\n",
      "0.4748407304286957\n",
      "0.46399790048599243\n",
      "0.45451459288597107\n",
      "0.4461713433265686\n",
      "0.43876659870147705\n",
      "0.43213340640068054\n",
      "0.4261389970779419\n",
      "0.42068004608154297\n",
      "0.41567546129226685\n",
      "0.41106146574020386\n",
      "0.4067873954772949\n",
      "0.40281081199645996\n",
      "0.3990974426269531\n",
      "0.395618200302124\n",
      "0.39234787225723267\n",
      "0.3892654478549957\n",
      "0.38635197281837463\n",
      "0.38359180092811584\n",
      "0.3809700310230255\n",
      "0.3784742057323456\n",
      "0.3760928809642792\n",
      "0.3738163709640503\n",
      "0.3716350197792053\n",
      "0.3695407509803772\n",
      "0.36752668023109436\n",
      "0.3655855655670166\n",
      "0.36371123790740967\n",
      "0.36189839243888855\n",
      "0.3601415753364563\n",
      "0.3584361672401428\n",
      "0.35677802562713623\n",
      "0.35516270995140076\n",
      "0.3535868525505066\n",
      "0.3520469665527344\n",
      "0.3505396246910095\n",
      "0.3490622043609619\n",
      "0.34761202335357666\n",
      "0.3461863696575165\n",
      "0.34478357434272766\n",
      "0.34340083599090576\n",
      "0.342036634683609\n",
      "0.3406897485256195\n",
      "0.3393583297729492\n",
      "0.3380417227745056\n",
      "0.3367385268211365\n",
      "0.3354485332965851\n",
      "0.334170937538147\n",
      "0.33290570974349976\n",
      "0.3316527307033539\n",
      "0.33041223883628845\n",
      "0.32918471097946167\n",
      "0.327970415353775\n",
      "0.3267703354358673\n",
      "0.3255850374698639\n",
      "0.3244157135486603\n",
      "0.3232627809047699\n",
      "0.3221275806427002\n",
      "0.32101088762283325\n",
      "0.3199136555194855\n",
      "0.318836510181427\n",
      "0.3177802860736847\n",
      "0.316745400428772\n",
      "0.31573256850242615\n",
      "0.31474220752716064\n",
      "0.3137742280960083\n",
      "0.31282907724380493\n",
      "0.3119065761566162\n",
      "0.31100672483444214\n",
      "0.3101293742656708\n",
      "0.30927401781082153\n",
      "0.30844077467918396\n",
      "0.30762889981269836\n",
      "0.30683812499046326\n",
      "0.30606788396835327\n",
      "0.30531764030456543\n",
      "0.30458709597587585\n",
      "0.3038754165172577\n",
      "0.30318212509155273\n",
      "0.30250680446624756\n",
      "0.301848828792572\n",
      "0.30120766162872314\n",
      "0.3005825877189636\n",
      "0.2999732196331024\n",
      "0.2993791401386261\n",
      "0.29879963397979736\n",
      "0.2982342839241028\n",
      "0.2976827621459961\n",
      "0.2971442937850952\n",
      "0.29661864042282104\n",
      "0.29610544443130493\n",
      "0.29560405015945435\n",
      "0.29511427879333496\n",
      "0.2946355938911438\n",
      "0.294167697429657\n",
      "0.2937101423740387\n",
      "0.2932628393173218\n",
      "0.2928251028060913\n",
      "0.29239681363105774\n",
      "0.29197773337364197\n",
      "0.2915674149990082\n",
      "0.29116564989089966\n",
      "0.2907722294330597\n",
      "0.29038679599761963\n",
      "0.29000914096832275\n",
      "0.2896389961242676\n",
      "0.289276123046875\n",
      "0.28892046213150024\n",
      "0.2885715663433075\n",
      "0.28822946548461914\n",
      "0.28789371252059937\n",
      "0.28756436705589294\n",
      "0.2872411012649536\n",
      "0.286923885345459\n",
      "0.28661227226257324\n",
      "0.28630635142326355\n",
      "0.2860058844089508\n",
      "0.28571075201034546\n",
      "0.285420686006546\n",
      "0.28513574600219727\n",
      "0.2848556935787201\n",
      "0.28458037972450256\n",
      "0.2843097448348999\n",
      "0.28404363989830017\n",
      "0.28378191590309143\n",
      "0.28352445363998413\n",
      "0.2832712233066559\n",
      "0.28302207589149475\n",
      "0.28277692198753357\n",
      "0.2825356423854828\n",
      "0.28229814767837524\n",
      "0.28206437826156616\n",
      "0.2818341851234436\n",
      "0.2816075086593628\n",
      "0.28138428926467896\n",
      "0.2811644673347473\n",
      "0.2809479236602783\n",
      "0.2807345390319824\n",
      "0.2805243730545044\n",
      "0.28031718730926514\n",
      "0.2801130414009094\n",
      "0.2799117863178253\n",
      "0.27971351146698\n",
      "0.2795180082321167\n",
      "0.2793251872062683\n",
      "0.2791350781917572\n",
      "0.2789476215839386\n",
      "0.27876269817352295\n",
      "0.27858033776283264\n",
      "0.2784004211425781\n",
      "0.278222918510437\n",
      "0.2780477702617645\n",
      "0.27787497639656067\n",
      "0.2777044475078583\n",
      "0.27753615379333496\n",
      "0.27736997604370117\n",
      "0.2772059440612793\n",
      "0.2770441174507141\n",
      "0.2768843173980713\n",
      "0.2767264246940613\n",
      "0.27657055854797363\n",
      "0.2764166593551636\n",
      "0.27626466751098633\n",
      "0.2761145532131195\n",
      "0.27596616744995117\n",
      "0.27581965923309326\n",
      "0.2756749987602234\n",
      "0.27553197741508484\n",
      "0.2753905951976776\n",
      "0.2752509117126465\n",
      "0.27511295676231384\n",
      "0.27497655153274536\n",
      "0.2748417258262634\n",
      "0.27470850944519043\n",
      "0.2745767831802368\n",
      "0.2744465470314026\n",
      "0.27431780099868774\n",
      "0.2741904854774475\n",
      "0.2740646004676819\n",
      "0.2739401161670685\n",
      "0.2738170325756073\n",
      "0.2736952304840088\n",
      "0.2735747992992401\n",
      "0.27345573902130127\n",
      "0.2733379006385803\n",
      "0.27322134375572205\n",
      "0.2731059789657593\n",
      "0.2729918956756592\n",
      "0.272879034280777\n",
      "0.2727673053741455\n",
      "0.27265676856040955\n",
      "0.2725474238395691\n",
      "0.272439181804657\n",
      "0.27233201265335083\n",
      "0.2722260057926178\n",
      "0.2721210718154907\n",
      "0.27201712131500244\n",
      "0.27191421389579773\n",
      "0.271812379360199\n",
      "0.2717116177082062\n",
      "0.2716117799282074\n",
      "0.2715129554271698\n",
      "0.2714150846004486\n",
      "0.2713181674480438\n",
      "0.27122217416763306\n",
      "0.2711271643638611\n",
      "0.2710329592227936\n",
      "0.27093976736068726\n",
      "0.2708474397659302\n",
      "0.27075594663619995\n",
      "0.27066531777381897\n",
      "0.270575612783432\n",
      "0.27048662304878235\n",
      "0.2703985869884491\n",
      "0.2703113257884979\n",
      "0.27022480964660645\n",
      "0.2701391279697418\n",
      "0.2700542211532593\n",
      "0.2699701189994812\n",
      "0.26988673210144043\n",
      "0.26980409026145935\n",
      "0.26972219347953796\n",
      "0.2696410119533539\n",
      "0.2695606052875519\n",
      "0.2694808542728424\n",
      "0.26940178871154785\n",
      "0.269323468208313\n",
      "0.26924577355384827\n",
      "0.2691688537597656\n",
      "0.26909250020980835\n",
      "0.2690168023109436\n",
      "0.2689417898654938\n",
      "0.26886746287345886\n",
      "0.26879364252090454\n",
      "0.26872050762176514\n",
      "0.26864802837371826\n",
      "0.26857611536979675\n",
      "0.268504798412323\n",
      "0.2684340476989746\n",
      "0.26836392283439636\n",
      "0.2682943642139435\n",
      "0.26822537183761597\n",
      "0.2681569457054138\n",
      "0.26808905601501465\n",
      "0.26802176237106323\n",
      "0.26795494556427\n",
      "0.2678886950016022\n",
      "0.2678229808807373\n",
      "0.26775771379470825\n",
      "0.26769307255744934\n",
      "0.26762890815734863\n",
      "0.2675652801990509\n",
      "0.2675021290779114\n",
      "0.2674393951892853\n",
      "0.26737722754478455\n",
      "0.26731547713279724\n",
      "0.2672543227672577\n",
      "0.2671935260295868\n",
      "0.2671331763267517\n",
      "0.267073392868042\n",
      "0.2670140266418457\n",
      "0.26695507764816284\n",
      "0.2668965458869934\n",
      "0.26683852076530457\n",
      "0.26678088307380676\n",
      "0.2667236924171448\n",
      "0.2666669189929962\n",
      "0.2666105628013611\n",
      "0.26655465364456177\n",
      "0.2664991319179535\n",
      "0.26644399762153625\n",
      "0.26638925075531006\n",
      "0.2663349509239197\n",
      "0.26628100872039795\n",
      "0.26622748374938965\n",
      "0.26617431640625\n",
      "0.2661215364933014\n",
      "0.2660691440105438\n",
      "0.2660171091556549\n",
      "0.26596540212631226\n",
      "0.2659141421318054\n",
      "0.26586318016052246\n",
      "0.26581260561943054\n",
      "0.2657623887062073\n",
      "0.2657124996185303\n",
      "0.26566293835639954\n",
      "0.26561373472213745\n",
      "0.265564888715744\n",
      "0.26551637053489685\n",
      "0.26546820998191833\n",
      "0.2654203176498413\n",
      "0.26537278294563293\n",
      "0.26532551646232605\n",
      "0.2652786374092102\n",
      "0.2652320861816406\n",
      "0.26518577337265015\n",
      "0.2651398479938507\n",
      "0.26509416103363037\n",
      "0.2650488018989563\n",
      "0.2650037109851837\n",
      "0.2649589776992798\n",
      "0.26491451263427734\n",
      "0.2648703157901764\n",
      "0.2648264467716217\n",
      "0.26478278636932373\n",
      "0.264739453792572\n",
      "0.2646963894367218\n",
      "0.26465368270874023\n",
      "0.2646111845970154\n",
      "0.26456889510154724\n",
      "0.26452693343162537\n",
      "0.264485239982605\n",
      "0.26444384455680847\n",
      "0.2644026577472687\n",
      "0.26436176896095276\n",
      "0.26432108879089355\n",
      "0.26428067684173584\n",
      "0.2642405331134796\n",
      "0.2642006278038025\n",
      "0.26416099071502686\n",
      "0.2641216218471527\n",
      "0.2640824615955353\n",
      "0.26404350996017456\n",
      "0.26400482654571533\n",
      "0.2639663517475128\n",
      "0.2639281451702118\n",
      "0.26389017701148987\n",
      "0.26385238766670227\n",
      "0.26381489634513855\n",
      "0.26377755403518677\n",
      "0.2637404501438141\n",
      "0.2637036144733429\n",
      "0.26366695761680603\n",
      "0.2636305093765259\n",
      "0.2635943293571472\n",
      "0.2635583281517029\n",
      "0.26352256536483765\n",
      "0.26348695158958435\n",
      "0.26345157623291016\n",
      "0.26341643929481506\n",
      "0.2633814811706543\n",
      "0.26334673166275024\n",
      "0.2633121609687805\n",
      "0.2632777988910675\n",
      "0.2632436454296112\n",
      "0.2632097005844116\n",
      "0.26317593455314636\n",
      "0.26314234733581543\n",
      "0.2631089687347412\n",
      "0.2630757689476013\n",
      "0.26304274797439575\n",
      "0.2630099654197693\n",
      "0.26297739148139954\n",
      "0.26294493675231934\n",
      "0.2629126310348511\n",
      "0.2628805637359619\n",
      "0.2628486752510071\n",
      "0.2628169655799866\n",
      "0.2627854347229004\n",
      "0.26275408267974854\n",
      "0.2627229392528534\n",
      "0.2626919150352478\n",
      "0.2626611292362213\n",
      "0.2626304626464844\n",
      "0.26260003447532654\n",
      "0.262569785118103\n",
      "0.26253971457481384\n",
      "0.26250985264778137\n",
      "0.2624801695346832\n",
      "0.262450635433197\n",
      "0.2624213397502899\n",
      "0.2623922526836395\n",
      "0.26236337423324585\n",
      "0.26233476400375366\n",
      "0.2623063325881958\n",
      "0.26227816939353943\n",
      "0.26225030422210693\n",
      "0.26222264766693115\n",
      "0.2621954083442688\n",
      "0.2621684670448303\n",
      "0.2621419131755829\n",
      "0.2621157467365265\n",
      "0.26209014654159546\n",
      "0.26206499338150024\n",
      "0.26204055547714233\n",
      "0.2620166838169098\n",
      "0.26199376583099365\n",
      "0.2619715929031372\n",
      "0.2619507312774658\n",
      "0.2619308829307556\n",
      "0.2619129419326782\n",
      "0.2618960738182068\n",
      "0.26188212633132935\n",
      "0.2618694603443146\n",
      "0.26186099648475647\n",
      "0.26185399293899536\n",
      "0.26185330748558044\n",
      "0.2618540823459625\n",
      "0.26186418533325195\n",
      "0.2618753910064697\n",
      "0.26190051436424255\n",
      "0.2619253396987915\n",
      "0.26197102665901184\n",
      "0.26201313734054565\n",
      "0.26208627223968506\n",
      "0.26214927434921265\n",
      "0.2622579336166382\n",
      "0.2623439133167267\n",
      "0.26249611377716064\n",
      "0.2626039981842041\n",
      "0.262805700302124\n",
      "0.26292821764945984\n",
      "0.26318052411079407\n",
      "0.2633025050163269\n",
      "0.2635985016822815\n",
      "0.26369708776474\n",
      "0.2640213072299957\n",
      "0.2640708386898041\n",
      "0.26440250873565674\n",
      "0.2643825113773346\n",
      "0.2647016644477844\n",
      "0.2646043598651886\n",
      "0.264897882938385\n",
      "0.2647295296192169\n",
      "0.26499322056770325\n",
      "0.26476964354515076\n",
      "0.2650054097175598\n",
      "0.2647445797920227\n",
      "0.26495739817619324\n",
      "0.2646753191947937\n",
      "0.26487019658088684\n",
      "0.2645784914493561\n",
      "0.26475971937179565\n",
      "0.2644660770893097\n",
      "0.2646363377571106\n",
      "0.264345645904541\n",
      "0.264506995677948\n",
      "0.2642216384410858\n",
      "0.2643751800060272\n",
      "0.26409685611724854\n",
      "0.2642437219619751\n",
      "0.26397305727005005\n",
      "0.26411375403404236\n",
      "0.2638510763645172\n",
      "0.2639860510826111\n",
      "0.2637314200401306\n",
      "0.2638612389564514\n",
      "0.2636144161224365\n",
      "0.2637392580509186\n",
      "0.2635001540184021\n",
      "0.26362037658691406\n",
      "0.26338860392570496\n",
      "0.2635044753551483\n",
      "0.2632799744606018\n",
      "0.2633916139602661\n",
      "0.2631739377975464\n",
      "0.26328152418136597\n",
      "0.26307055354118347\n",
      "0.2631746232509613\n",
      "0.26297006011009216\n",
      "0.2630705237388611\n",
      "0.26287198066711426\n",
      "0.2629690170288086\n",
      "0.26277631521224976\n",
      "0.2628701329231262\n",
      "0.2626830041408539\n",
      "0.262773722410202\n",
      "0.2625918686389923\n",
      "0.26267972588539124\n",
      "0.26250308752059937\n",
      "0.26258814334869385\n",
      "0.26241636276245117\n",
      "0.262498676776886\n",
      "0.26233163475990295\n",
      "0.262411504983902\n",
      "0.2622489929199219\n",
      "0.2623263895511627\n",
      "0.26216810941696167\n",
      "0.2622431516647339\n",
      "0.2620890140533447\n",
      "0.26216185092926025\n",
      "0.2620117962360382\n",
      "0.2620825469493866\n",
      "0.261936217546463\n",
      "0.2620049715042114\n",
      "0.2618623971939087\n",
      "0.2619291841983795\n",
      "0.26179009675979614\n",
      "0.2618550658226013\n",
      "0.2617194354534149\n",
      "0.2617826461791992\n",
      "0.2616502046585083\n",
      "0.2617117762565613\n",
      "0.26158246397972107\n",
      "0.2616424262523651\n",
      "0.26151609420776367\n",
      "0.26157450675964355\n",
      "0.26145103573799133\n",
      "0.26150792837142944\n",
      "0.26138728857040405\n",
      "0.26144278049468994\n",
      "0.2613246738910675\n",
      "0.26137882471084595\n",
      "0.2612634003162384\n",
      "0.2613162398338318\n",
      "0.26120325922966003\n",
      "0.26125484704971313\n",
      "0.2611442804336548\n",
      "0.26119470596313477\n",
      "0.2610864043235779\n",
      "0.2611357271671295\n",
      "0.2610296607017517\n",
      "0.2610778510570526\n",
      "0.2609739601612091\n",
      "0.26102107763290405\n",
      "0.2609192132949829\n",
      "0.2609652876853943\n",
      "0.26086533069610596\n",
      "0.2609104514122009\n",
      "0.2608124613761902\n",
      "0.26085659861564636\n",
      "0.26076045632362366\n",
      "0.26080381870269775\n",
      "0.2607094943523407\n",
      "0.26075196266174316\n",
      "0.2606593072414398\n",
      "0.2607009708881378\n",
      "0.26061001420021057\n",
      "0.26065078377723694\n",
      "0.26056137681007385\n",
      "0.2606015205383301\n",
      "0.26051369309425354\n",
      "0.2605530321598053\n",
      "0.26046669483184814\n",
      "0.26050540804862976\n",
      "0.2604205310344696\n",
      "0.2604585886001587\n",
      "0.26037511229515076\n",
      "0.2604125142097473\n",
      "0.26033028960227966\n",
      "0.2603669762611389\n",
      "0.26028621196746826\n",
      "0.2603221833705902\n",
      "0.26024261116981506\n",
      "0.2602781057357788\n",
      "0.2601996958255768\n",
      "0.26023462414741516\n",
      "0.26015743613243103\n",
      "0.2601918578147888\n",
      "0.2601158618927002\n",
      "0.26014965772628784\n",
      "0.2600747346878052\n",
      "0.2601080536842346\n",
      "0.2600342929363251\n",
      "0.2600671947002411\n",
      "0.2599944770336151\n",
      "0.2600269317626953\n",
      "0.25995516777038574\n",
      "0.25998711585998535\n",
      "0.2599162459373474\n",
      "0.2599477469921112\n",
      "0.25987792015075684\n",
      "0.2599089741706848\n",
      "0.2598400413990021\n",
      "0.2598707377910614\n",
      "0.2598026692867279\n",
      "0.2598329782485962\n",
      "0.2597658634185791\n",
      "0.2597958445549011\n",
      "0.2597294747829437\n",
      "0.25975897908210754\n",
      "0.2596935033798218\n",
      "0.25972262024879456\n",
      "0.25965791940689087\n",
      "0.25968676805496216\n",
      "0.25962284207344055\n",
      "0.2596513032913208\n",
      "0.2595881521701813\n",
      "0.25961628556251526\n",
      "0.2595538794994354\n",
      "0.25958168506622314\n",
      "0.2595199644565582\n",
      "0.25954747200012207\n",
      "0.25948643684387207\n",
      "0.2595137059688568\n",
      "0.2594534158706665\n",
      "0.259480357170105\n",
      "0.2594206929206848\n",
      "0.259447306394577\n",
      "0.259388267993927\n",
      "0.2594146132469177\n",
      "0.25935620069503784\n",
      "0.25938236713409424\n",
      "0.2593245506286621\n",
      "0.25935038924217224\n",
      "0.25929319858551025\n",
      "0.2593187987804413\n",
      "0.25926220417022705\n",
      "0.25928762555122375\n",
      "0.2592315375804901\n",
      "0.25925666093826294\n",
      "0.25920116901397705\n",
      "0.2592260539531708\n",
      "0.25917109847068787\n",
      "0.25919580459594727\n",
      "0.25914135575294495\n",
      "0.25916576385498047\n",
      "0.2591119110584259\n",
      "0.2591360807418823\n",
      "0.2590826749801636\n",
      "0.25910669565200806\n",
      "0.2590537667274475\n",
      "0.2590775787830353\n",
      "0.25902512669563293\n",
      "0.259048730134964\n",
      "0.258996844291687\n",
      "0.25902029871940613\n",
      "0.258968710899353\n",
      "0.25899195671081543\n",
      "0.2589409351348877\n",
      "0.25896403193473816\n",
      "0.25891342759132385\n",
      "0.25893622636795044\n",
      "0.25888603925704956\n",
      "0.2589087188243866\n",
      "0.25885891914367676\n",
      "0.2588813602924347\n",
      "0.25883200764656067\n",
      "0.2588542699813843\n",
      "0.2588052749633789\n",
      "0.2588273882865906\n",
      "0.2587788701057434\n",
      "0.25880077481269836\n",
      "0.2587526738643646\n",
      "0.2587744891643524\n",
      "0.25872674584388733\n",
      "0.2587484121322632\n",
      "0.25870102643966675\n",
      "0.2587224841117859\n",
      "0.2586754858493805\n",
      "0.25869685411453247\n",
      "0.25865012407302856\n",
      "0.25867128372192383\n",
      "0.25862497091293335\n",
      "0.25864604115486145\n",
      "0.25860002636909485\n",
      "0.2586209177970886\n",
      "0.2585752606391907\n",
      "0.2585960030555725\n",
      "0.2585506737232208\n",
      "0.25857123732566833\n",
      "0.25852635502815247\n",
      "0.2585468292236328\n",
      "0.2585022449493408\n",
      "0.25852254033088684\n",
      "0.2584782540798187\n",
      "0.2584984302520752\n",
      "0.25845441222190857\n",
      "0.2584744691848755\n",
      "0.2584307789802551\n",
      "0.2584507167339325\n",
      "0.2584073543548584\n",
      "0.25842714309692383\n",
      "0.2583840787410736\n",
      "0.2584036886692047\n",
      "0.258360892534256\n",
      "0.2583804130554199\n",
      "0.2583378553390503\n",
      "0.25835731625556946\n",
      "0.2583151161670685\n",
      "0.2583343982696533\n",
      "0.25829243659973145\n",
      "0.2583114802837372\n",
      "0.25826990604400635\n",
      "0.2582888603210449\n",
      "0.2582474946975708\n",
      "0.2582663893699646\n",
      "0.25822532176971436\n",
      "0.2582440972328186\n",
      "0.25820332765579224\n",
      "0.25822195410728455\n",
      "0.2581813931465149\n",
      "0.25819987058639526\n",
      "0.2581596076488495\n",
      "0.2581780254840851\n",
      "0.258137971162796\n",
      "0.25815629959106445\n",
      "0.25811654329299927\n",
      "0.25813472270965576\n",
      "0.25809523463249207\n",
      "0.25811320543289185\n",
      "0.25807395577430725\n",
      "0.25809192657470703\n",
      "0.2580529451370239\n",
      "0.25807079672813416\n",
      "0.25803202390670776\n",
      "0.25804969668388367\n",
      "0.2580111622810364\n",
      "0.2580287456512451\n",
      "0.2579904794692993\n",
      "0.2580079138278961\n",
      "0.2579698860645294\n",
      "0.25798726081848145\n",
      "0.2579495310783386\n",
      "0.25796669721603394\n",
      "0.2579291760921478\n",
      "0.257946252822876\n",
      "0.2579089105129242\n",
      "0.2579258978366852\n",
      "0.2578888237476349\n",
      "0.2579057514667511\n",
      "0.2578689455986023\n",
      "0.25788575410842896\n",
      "0.25784915685653687\n",
      "0.25786593556404114\n",
      "0.25782954692840576\n",
      "0.2578461170196533\n",
      "0.2578098773956299\n",
      "0.2578263580799103\n",
      "0.2577904462814331\n",
      "0.25780683755874634\n",
      "0.2577711343765259\n",
      "0.25778740644454956\n",
      "0.2577518820762634\n",
      "0.25776809453964233\n",
      "0.2577327787876129\n",
      "0.2577488422393799\n",
      "0.25771376490592957\n",
      "0.2577296793460846\n",
      "0.257694810628891\n",
      "0.25771060585975647\n",
      "0.2576759457588196\n",
      "0.25769171118736267\n",
      "0.2576572000980377\n",
      "0.25767284631729126\n",
      "0.2576385736465454\n",
      "0.2576541304588318\n",
      "0.25762009620666504\n",
      "0.25763559341430664\n",
      "0.25760170817375183\n",
      "0.2576170265674591\n",
      "0.257583349943161\n",
      "0.2575985789299011\n",
      "0.25756514072418213\n",
      "0.25758033990859985\n",
      "0.25754714012145996\n",
      "0.25756219029426575\n",
      "0.2575291693210602\n",
      "0.2575441300868988\n",
      "0.25751128792762756\n",
      "0.25752609968185425\n",
      "0.25749343633651733\n",
      "0.25750818848609924\n",
      "0.25747573375701904\n",
      "0.2574903964996338\n",
      "0.2574580907821655\n",
      "0.2574726343154907\n",
      "0.25744056701660156\n",
      "0.2574550211429596\n",
      "0.25742313265800476\n",
      "0.25743749737739563\n",
      "0.2574058175086975\n",
      "0.2574201226234436\n",
      "0.2573886513710022\n",
      "0.25740280747413635\n",
      "0.2573715150356293\n",
      "0.2573855519294739\n",
      "0.2573544681072235\n",
      "0.25736841559410095\n",
      "0.2573375105857849\n",
      "0.2573513984680176\n",
      "0.2573206424713135\n",
      "0.25733453035354614\n",
      "0.2573038935661316\n",
      "0.2573176324367523\n",
      "0.2572872042655945\n",
      "0.25730082392692566\n",
      "0.2572706341743469\n",
      "0.25728416442871094\n",
      "0.2572541832923889\n",
      "0.2572675943374634\n",
      "0.2572377324104309\n",
      "0.25725117325782776\n",
      "0.2572214901447296\n",
      "0.25723475217819214\n",
      "0.2572052478790283\n",
      "0.2572183907032013\n",
      "0.2571890652179718\n",
      "0.2572021186351776\n",
      "0.25717297196388245\n",
      "0.2571859359741211\n",
      "0.25715696811676025\n",
      "0.25716981291770935\n",
      "0.2571410834789276\n",
      "0.2571538984775543\n",
      "0.25712525844573975\n",
      "0.2571379542350769\n",
      "0.25710949301719666\n",
      "0.25712212920188904\n",
      "0.2570938467979431\n",
      "0.25710633397102356\n",
      "0.25707823038101196\n",
      "0.2570907473564148\n",
      "0.25706279277801514\n",
      "0.25707513093948364\n",
      "0.2570473551750183\n",
      "0.25705966353416443\n",
      "0.25703194737434387\n",
      "0.2570441961288452\n",
      "0.25701671838760376\n",
      "0.25702884793281555\n",
      "0.2570015490055084\n",
      "0.25701361894607544\n",
      "0.25698646903038025\n",
      "0.2569984197616577\n",
      "0.2569713592529297\n",
      "0.2569832503795624\n",
      "0.25695639848709106\n",
      "0.2569682002067566\n",
      "0.2569414973258972\n",
      "0.2569531798362732\n",
      "0.25692659616470337\n",
      "0.25693824887275696\n",
      "0.25691187381744385\n",
      "0.2569234371185303\n",
      "0.2568972408771515\n",
      "0.25690871477127075\n",
      "0.2568826377391815\n",
      "0.2568940818309784\n",
      "0.2568681240081787\n",
      "0.2568794786930084\n",
      "0.25685369968414307\n",
      "0.256864994764328\n",
      "0.2568393349647522\n",
      "0.25685060024261475\n",
      "0.2568250894546509\n",
      "0.2568362355232239\n",
      "0.25681090354919434\n",
      "0.2568219304084778\n",
      "0.2567967176437378\n",
      "0.25680768489837646\n",
      "0.2567826509475708\n",
      "0.2567935585975647\n",
      "0.2567686438560486\n",
      "0.2567794620990753\n",
      "0.25675472617149353\n",
      "0.2567654848098755\n",
      "0.2567408084869385\n",
      "0.25675153732299805\n",
      "0.25672706961631775\n",
      "0.25673770904541016\n",
      "0.2567133903503418\n",
      "0.25672388076782227\n",
      "0.25669968128204346\n",
      "0.25671008229255676\n",
      "0.2566860616207123\n",
      "0.2566964030265808\n",
      "0.25667256116867065\n",
      "0.2566828429698944\n",
      "0.25665903091430664\n",
      "0.25666916370391846\n",
      "0.2566456198692322\n",
      "0.25665581226348877\n",
      "0.25663232803344727\n",
      "0.2566423714160919\n",
      "0.2566189765930176\n",
      "0.2566290497779846\n",
      "0.2566058039665222\n",
      "0.2566158175468445\n",
      "0.2565927803516388\n",
      "0.2566026747226715\n",
      "0.256579726934433\n",
      "0.25658953189849854\n",
      "0.25656670331954956\n",
      "0.25657644867897034\n",
      "0.2565537691116333\n",
      "0.2565634250640869\n",
      "0.25654083490371704\n",
      "0.25655046105384827\n",
      "0.25652801990509033\n",
      "0.2565375566482544\n",
      "0.256515234708786\n",
      "0.2565246820449829\n",
      "0.25650253891944885\n",
      "0.256511926651001\n",
      "0.2564898431301117\n",
      "0.25649920105934143\n",
      "0.2564772963523865\n",
      "0.25648656487464905\n",
      "0.25646474957466125\n",
      "0.25647395849227905\n",
      "0.2564522624015808\n",
      "0.25646138191223145\n",
      "0.25643983483314514\n",
      "0.2564489245414734\n",
      "0.25642749667167664\n",
      "0.2564365565776825\n",
      "0.25641515851020813\n",
      "0.2564241588115692\n",
      "0.25640296936035156\n",
      "0.25641191005706787\n",
      "0.256390780210495\n",
      "0.25639963150024414\n",
      "0.2563786506652832\n",
      "0.25638750195503235\n",
      "0.25636664032936096\n",
      "0.25637534260749817\n",
      "0.25635460019111633\n",
      "0.25636327266693115\n",
      "0.25634264945983887\n",
      "0.2563512623310089\n",
      "0.2563307285308838\n",
      "0.25633931159973145\n",
      "0.25631892681121826\n",
      "0.25632745027542114\n",
      "0.25630712509155273\n",
      "0.25631555914878845\n",
      "0.2562953531742096\n",
      "0.2563037872314453\n",
      "0.2562837600708008\n",
      "0.2562921643257141\n",
      "0.25627222657203674\n",
      "0.25628048181533813\n",
      "0.25626060366630554\n",
      "0.25626879930496216\n",
      "0.2562491297721863\n",
      "0.2562572658061981\n",
      "0.25623756647109985\n",
      "0.2562457323074341\n",
      "0.25622624158859253\n",
      "0.2562342882156372\n",
      "0.2562148869037628\n",
      "0.2562228739261627\n",
      "0.2562035620212555\n",
      "0.2562115788459778\n",
      "0.2561923563480377\n",
      "0.25620022416114807\n",
      "0.25618118047714233\n",
      "0.2561889886856079\n",
      "0.25617003440856934\n",
      "0.2561778128147125\n",
      "0.2561589479446411\n",
      "0.2561666667461395\n",
      "0.2561478912830353\n",
      "0.2561556100845337\n",
      "0.2561368942260742\n"
     ]
    }
   ],
   "source": [
    "for _ in range(1000):\n",
    "    # forward pass\n",
    "    emb = C[X]\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    # counts = logits.exp()\n",
    "    # probs = counts / counts.sum(1, keepdim=True)\n",
    "    # loss = -probs[torch.arange(32), Y].log().mean()\n",
    "    loss = F.cross_entropy(logits, Y)\n",
    "    print(loss.item())\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    # update \n",
    "    for p in parameters:\n",
    "        p.data += -0.1 * p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2561, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.7421e+00,  1.3235e+01,  5.3940e+00,  4.0988e+00, -7.6535e-01,\n",
       "          1.3222e+01, -1.8069e+01,  5.7285e+00, -3.5979e+00,  1.3118e+01,\n",
       "          6.8001e+00, -3.3704e+00, -1.8751e-01,  7.3862e+00,  3.0223e-01,\n",
       "          1.3197e+01,  3.6976e+00,  6.6991e+00, -7.2902e-01,  1.3335e+01,\n",
       "         -2.3995e+00,  4.7283e+00,  7.0238e+00, -6.4949e+00,  6.4408e+00,\n",
       "         -5.4583e+00,  5.9195e+00],\n",
       "        [-9.0184e+00,  7.5491e+00,  1.9528e+00,  1.4233e+00,  5.6973e+00,\n",
       "          9.9765e+00, -2.4487e+00,  4.2988e+00,  8.6141e+00, -3.7782e+00,\n",
       "          1.0311e+01, -9.6241e-01,  1.2333e+01,  1.7791e+01,  5.8880e+00,\n",
       "          6.2631e+00,  8.7805e+00,  1.9645e+00,  7.4622e+00,  9.4323e+00,\n",
       "          1.9641e+00, -9.0605e+00, -9.9813e+00, -1.1730e+01,  1.6828e+00,\n",
       "         -4.0623e+00,  6.2619e+00],\n",
       "        [ 8.0140e+00,  1.1974e+01,  1.0477e+01,  5.6248e+00, -1.9768e+00,\n",
       "          5.6115e+00, -9.9594e+00, -8.7409e+00, -1.1285e+01,  1.4137e+01,\n",
       "          5.7153e+00,  1.1738e+01,  5.3283e+00,  2.0601e+01, -1.2175e+01,\n",
       "          5.0475e+00, -7.3166e+00, -1.2202e+01, -7.2425e+00, -2.3980e+00,\n",
       "         -2.3431e+00, -1.8987e+00, -4.2422e-01,  1.3486e+01,  3.6283e+00,\n",
       "         -1.6037e+01,  1.3035e+00],\n",
       "        [ 1.4267e+01,  2.0612e+01,  8.0008e+00, -1.2029e+00, -1.5340e+01,\n",
       "          4.2617e+00,  5.0010e+00, -1.7259e+00,  6.6228e+00,  1.1217e+01,\n",
       "         -1.1674e+01,  1.2571e+01, -1.6159e+01,  2.1755e+00,  6.8709e+00,\n",
       "         -2.0942e+00,  3.7999e+00,  7.0506e+00,  1.9731e+00,  5.7065e+00,\n",
       "          1.2936e-01,  8.5654e+00,  1.3333e+01, -2.0069e+01, -4.1017e+00,\n",
       "          1.0950e+01, -2.0098e+00],\n",
       "        [ 1.6736e+01,  9.2573e+00,  4.5319e+00,  2.3472e+00, -4.3785e+00,\n",
       "          6.6229e-01, -9.9294e+00, -6.7678e-01, -1.0363e+00,  7.6039e+00,\n",
       "          1.3426e-01, -3.9395e+00,  1.6787e+00,  2.5192e+00,  5.3516e+00,\n",
       "          6.2471e+00,  5.8306e+00, -1.0980e+00,  1.5607e+00,  9.6972e+00,\n",
       "          5.1263e+00,  5.6754e+00,  1.0208e+01, -7.8229e+00, -3.7744e+00,\n",
       "          2.1275e+00,  2.9816e+00],\n",
       "        [ 3.7421e+00,  1.3235e+01,  5.3940e+00,  4.0988e+00, -7.6535e-01,\n",
       "          1.3222e+01, -1.8069e+01,  5.7285e+00, -3.5979e+00,  1.3118e+01,\n",
       "          6.8001e+00, -3.3704e+00, -1.8751e-01,  7.3862e+00,  3.0223e-01,\n",
       "          1.3197e+01,  3.6976e+00,  6.6991e+00, -7.2902e-01,  1.3335e+01,\n",
       "         -2.3995e+00,  4.7283e+00,  7.0238e+00, -6.4949e+00,  6.4408e+00,\n",
       "         -5.4583e+00,  5.9195e+00],\n",
       "        [-3.3487e+00,  7.4352e+00,  3.4512e+00, -1.0771e+00,  3.6266e+00,\n",
       "          7.4474e+00,  9.9045e-01, -5.9414e-02,  3.9128e+00, -2.6372e+00,\n",
       "          8.6433e+00, -4.3205e+00,  1.5999e+01,  1.0148e+01,  9.7267e-01,\n",
       "          8.2031e+00,  7.5635e+00,  5.3743e+00,  8.3914e+00,  9.9079e+00,\n",
       "          1.4084e+00, -3.3366e+00, -4.1966e+00, -1.5224e+01, -9.3528e-02,\n",
       "         -1.1539e+00,  5.9436e+00],\n",
       "        [-1.2178e+01,  1.4580e+00,  4.7735e+00, -1.8679e+00,  5.7862e+00,\n",
       "          1.3294e+00, -3.3010e+00, -1.4443e+01,  4.2033e+00,  1.4172e+01,\n",
       "          5.9771e+00, -2.5746e+00,  7.8103e+00, -4.3485e+00, -3.5194e+00,\n",
       "          4.2908e+00, -8.8181e-01, -2.3496e+00, -3.9363e+00, -6.3411e+00,\n",
       "         -1.2335e+01, -1.2714e+01, -1.0422e+01,  4.8424e+00,  4.2428e+00,\n",
       "         -4.1691e+00,  5.2854e+00],\n",
       "        [ 9.2521e+00,  1.5832e+00,  3.0854e+00, -6.5476e+00, -3.7128e+00,\n",
       "          3.5229e-01, -8.6984e+00, -1.2585e+01, -1.1194e+01,  9.9824e+00,\n",
       "          8.1250e+00,  4.1423e+00, -1.1283e+01, -2.2876e+00, -1.7385e+01,\n",
       "          2.6958e-01, -1.9144e+01, -4.3970e+00, -2.5039e+00, -3.3980e+00,\n",
       "          2.9907e-01, -2.9385e+00,  1.5915e+01,  2.3263e+00,  7.4784e-01,\n",
       "         -3.9261e+00, -1.7952e+01],\n",
       "        [ 1.0003e+01,  1.2034e+01,  2.9775e+00,  4.5981e+00, -3.0994e+00,\n",
       "          2.3943e+00,  2.5704e+00, -3.4343e+00, -9.0495e+00,  1.8361e+01,\n",
       "          4.4450e+00,  7.6127e+00, -1.3156e+01, -1.7073e+00, -1.9535e+00,\n",
       "         -7.0361e+00, -9.9718e-01,  8.0882e+00,  6.3448e+00,  3.4179e+00,\n",
       "          8.9709e-01,  7.7363e+00,  1.0957e+01, -1.2787e+01,  4.1832e+00,\n",
       "         -9.2536e-01, -2.5068e+00],\n",
       "        [ 1.0020e+01,  1.5940e+01,  8.7894e+00,  4.5785e+00, -9.1835e+00,\n",
       "          9.6307e+00, -1.0313e+01,  4.7396e+00,  4.5160e+00,  7.1112e+00,\n",
       "         -1.2756e+00,  4.7333e+00,  8.5019e-01,  4.6710e+00,  5.6065e+00,\n",
       "          3.7634e+00,  6.1408e+00,  2.4016e+00,  4.1308e+00,  1.2444e+00,\n",
       "         -1.2685e+00,  1.0306e+00,  4.8057e+00, -1.0815e+01, -8.0338e+00,\n",
       "          3.4748e+00,  3.4956e+00],\n",
       "        [ 2.0926e+01,  1.3634e+01,  9.3966e+00,  4.2861e+00, -7.7587e+00,\n",
       "         -1.2080e-01, -3.8335e+00, -1.2424e+00,  2.2029e+00,  9.6256e+00,\n",
       "         -2.4219e+00,  1.1996e+00,  2.5983e+00,  8.2391e+00,  9.7597e+00,\n",
       "          5.9493e+00,  4.0705e+00, -4.6063e-01,  9.5916e-01, -5.9135e+00,\n",
       "          7.8206e+00, -9.0623e-01,  1.0292e+01, -4.7415e+00, -8.2072e+00,\n",
       "          4.0394e+00, -1.5983e+00],\n",
       "        [ 3.7421e+00,  1.3235e+01,  5.3940e+00,  4.0988e+00, -7.6535e-01,\n",
       "          1.3222e+01, -1.8069e+01,  5.7285e+00, -3.5979e+00,  1.3118e+01,\n",
       "          6.8001e+00, -3.3704e+00, -1.8751e-01,  7.3862e+00,  3.0223e-01,\n",
       "          1.3197e+01,  3.6976e+00,  6.6991e+00, -7.2902e-01,  1.3335e+01,\n",
       "         -2.3995e+00,  4.7283e+00,  7.0238e+00, -6.4949e+00,  6.4408e+00,\n",
       "         -5.4583e+00,  5.9195e+00],\n",
       "        [ 1.1238e+01,  1.1299e+01,  4.6458e+00,  1.7194e-01,  3.0389e-01,\n",
       "         -2.3649e+00, -1.1337e+01, -3.1906e+00, -2.7136e+00,  9.6527e+00,\n",
       "          1.8837e+00, -4.4558e+00,  1.2644e+00,  3.2120e+00,  3.7409e-01,\n",
       "          1.2567e+01,  5.2273e+00,  1.6042e+00,  1.2822e+00,  9.7342e+00,\n",
       "          5.2840e+00,  5.0333e+00,  1.7109e+01, -7.5678e+00, -1.2492e+00,\n",
       "         -5.4544e+00,  2.6319e+00],\n",
       "        [ 1.6655e+00,  1.7132e+01,  5.1584e+00,  1.7462e+00, -9.8913e-01,\n",
       "          9.5384e+00, -8.7046e+00,  5.4568e+00, -1.9901e+00,  7.5224e+00,\n",
       "          3.9720e+00,  1.4269e+00,  6.1898e+00,  6.6421e+00, -2.4853e+00,\n",
       "          4.0191e+00,  8.5835e+00, -6.0672e-01,  5.0451e+00, -9.7104e-02,\n",
       "         -9.6156e+00, -4.2296e-02,  4.3452e+00, -9.9640e+00, -2.7047e+00,\n",
       "          2.8345e+00,  7.4191e+00],\n",
       "        [ 2.0060e+01,  1.1126e+01,  1.1881e+01,  3.9288e+00, -9.4695e+00,\n",
       "          1.6122e+00, -3.2179e+00,  7.6492e-01,  3.5853e+00,  9.3344e+00,\n",
       "         -5.1467e-01,  1.3666e+00,  3.0666e+00,  5.1596e+00,  1.1931e+01,\n",
       "          4.8317e+00,  6.2411e+00, -3.5192e-01, -2.1422e+00, -8.9265e+00,\n",
       "          8.3941e+00, -9.0002e-01,  1.1132e+01, -5.9238e+00, -9.9133e+00,\n",
       "          6.7421e+00, -9.5345e-01],\n",
       "        [ 3.7421e+00,  1.3235e+01,  5.3940e+00,  4.0988e+00, -7.6535e-01,\n",
       "          1.3222e+01, -1.8069e+01,  5.7285e+00, -3.5979e+00,  1.3118e+01,\n",
       "          6.8001e+00, -3.3704e+00, -1.8751e-01,  7.3862e+00,  3.0223e-01,\n",
       "          1.3197e+01,  3.6976e+00,  6.6991e+00, -7.2902e-01,  1.3335e+01,\n",
       "         -2.3995e+00,  4.7283e+00,  7.0238e+00, -6.4949e+00,  6.4408e+00,\n",
       "         -5.4583e+00,  5.9195e+00],\n",
       "        [ 8.8500e+00,  1.0988e+01, -1.8066e-01,  3.1241e+00,  3.0713e+00,\n",
       "          2.9694e+00, -1.4993e+01,  4.8535e+00, -3.0152e+00,  6.9465e+00,\n",
       "          4.7202e+00, -1.6046e+00,  6.0235e+00,  6.0101e+00,  1.0652e+00,\n",
       "          1.0831e+01,  3.0950e+00,  1.9978e+00,  2.2872e+00,  1.6589e+01,\n",
       "          1.9353e+00,  7.9643e+00,  7.3125e+00, -8.1322e+00,  4.9393e+00,\n",
       "         -7.8206e+00,  3.7411e+00],\n",
       "        [ 9.1367e+00,  1.5102e+01,  5.8050e+00,  1.5209e+00, -3.2267e+00,\n",
       "         -8.2199e-01, -3.7323e+00, -1.9496e+00, -5.1282e+00,  8.2042e+00,\n",
       "          2.6964e+00, -6.0617e+00,  8.7303e+00,  2.0121e+00, -1.9688e+00,\n",
       "          9.4258e+00,  5.1745e+00, -1.4287e+00,  2.4093e+00,  3.3304e+00,\n",
       "          2.4125e+00, -7.9427e-01,  7.8552e+00, -9.0882e+00, -3.7356e+00,\n",
       "         -1.9957e+00,  2.0509e+00],\n",
       "        [ 8.6555e+00,  1.0337e+01,  1.7058e+01, -1.2848e+00, -1.4659e+01,\n",
       "          5.5003e+00, -6.5663e+00,  6.4121e+00,  1.3197e+00,  9.4395e+00,\n",
       "          6.3876e-01,  5.5610e+00,  2.2345e+00,  6.2699e+00,  9.4608e+00,\n",
       "         -2.7704e+00,  6.6613e+00,  2.8922e+00,  8.0534e+00, -1.0554e+01,\n",
       "          2.2471e+00, -4.1877e+00,  7.6948e+00, -6.8317e+00, -7.5686e+00,\n",
       "          1.3206e+00, -7.0992e-01],\n",
       "        [-3.7777e+00, -1.2866e+00,  2.9300e+00, -2.9833e-01,  1.7042e+00,\n",
       "          1.8586e+01,  2.4533e-01,  1.1212e+01,  7.1292e+00, -1.9014e+00,\n",
       "          3.1350e-01,  4.7065e+00,  7.4266e-01, -3.4584e-01,  1.0073e+01,\n",
       "          2.7744e+00,  1.1869e+01,  5.9112e+00, -2.3595e+00, -3.6913e+00,\n",
       "         -1.0901e+01, -1.3041e+01,  7.8295e+00, -1.0066e+01, -7.0970e+00,\n",
       "          1.1543e+01, -5.1142e+00],\n",
       "        [-2.8037e+00, -3.1279e+00, -3.7810e+00, -9.0339e-02,  9.0572e+00,\n",
       "          8.1230e+00, -3.0407e+00, -7.5571e+00,  7.2181e+00, -2.1304e+00,\n",
       "          4.7204e+00,  7.1083e+00,  1.5967e+01,  2.6214e+00, -3.2701e+00,\n",
       "          6.2168e+00,  2.7224e+00, -3.6140e-01,  1.2360e-02, -4.8249e+00,\n",
       "         -3.5248e+00, -1.6936e+01, -1.5680e+00,  1.8258e+00, -6.8284e+00,\n",
       "          2.7481e-01, -4.0817e+00],\n",
       "        [-1.8289e+01,  4.8778e+00,  1.9569e+00,  7.2987e-01, -2.1446e+00,\n",
       "         -9.0169e+00, -1.0463e+00, -2.2897e+01,  1.2370e+00,  1.0675e+00,\n",
       "          3.3542e+00,  3.2479e+00,  1.0874e+01, -7.9104e+00, -2.4293e+00,\n",
       "         -4.3977e+00, -1.1491e+01, -1.1501e+01, -3.0162e+00, -9.8570e+00,\n",
       "         -9.0820e+00, -2.2539e+00, -7.4693e+00, -2.0140e+00, -3.2170e+00,\n",
       "         -5.0396e-01,  3.7870e+00],\n",
       "        [-1.0344e+01,  1.0687e+01, -5.0980e-01,  2.5173e+00,  2.7360e+00,\n",
       "         -6.7384e+00, -1.0232e+01, -1.9884e+01, -2.6190e+00,  4.5211e+00,\n",
       "          2.5943e-01, -8.0216e-01,  5.4700e-02, -8.6969e+00, -7.0920e+00,\n",
       "         -3.5161e+00, -1.9470e+01, -7.9932e+00,  2.4875e+00,  4.0261e+00,\n",
       "         -5.3181e+00, -1.7766e+00, -9.4089e+00,  2.1977e+00,  5.6617e-01,\n",
       "         -1.0533e+01,  3.0982e+00],\n",
       "        [ 1.5506e+01,  7.8151e+00,  6.1576e+00, -5.3347e-01,  1.8776e+00,\n",
       "         -1.9659e+00, -1.0523e+01, -8.9839e+00, -1.4726e+01,  6.7407e+00,\n",
       "          7.2602e+00,  8.3379e+00, -8.4933e+00, -4.0459e+00, -1.8501e+01,\n",
       "          2.6517e+00, -1.5573e+01, -8.0174e+00, -5.4466e+00,  3.8502e+00,\n",
       "          6.9754e+00,  7.9984e+00,  3.9985e+00,  5.3624e+00,  3.6816e+00,\n",
       "         -1.6663e+01, -2.1514e+00],\n",
       "        [ 3.7421e+00,  1.3235e+01,  5.3940e+00,  4.0988e+00, -7.6535e-01,\n",
       "          1.3222e+01, -1.8069e+01,  5.7285e+00, -3.5979e+00,  1.3118e+01,\n",
       "          6.8001e+00, -3.3704e+00, -1.8751e-01,  7.3862e+00,  3.0223e-01,\n",
       "          1.3197e+01,  3.6976e+00,  6.6991e+00, -7.2902e-01,  1.3335e+01,\n",
       "         -2.3995e+00,  4.7283e+00,  7.0238e+00, -6.4949e+00,  6.4408e+00,\n",
       "         -5.4583e+00,  5.9195e+00],\n",
       "        [ 6.7622e+00,  9.9275e+00,  9.5580e+00, -1.6441e+00, -2.6242e+00,\n",
       "         -2.1053e+00, -8.8274e+00, -2.7570e+00, -4.3407e+00,  6.4778e+00,\n",
       "          3.0166e+00, -7.7866e+00,  2.8746e+00,  2.8324e-01, -2.5693e+00,\n",
       "          1.6179e+01,  3.1822e+00,  2.6444e+00,  9.3127e-01,  1.0177e+01,\n",
       "          5.0403e+00,  3.9669e+00,  1.1506e+01, -1.0614e+01, -1.0368e+00,\n",
       "         -5.2692e+00,  2.5753e+00],\n",
       "        [-9.7464e+00,  5.4707e+00, -3.6185e+00, -2.5072e+00,  4.5218e+00,\n",
       "          5.8613e+00, -8.5584e-01,  9.0580e+00,  8.3851e+00, -2.9877e+00,\n",
       "         -2.1189e+00,  5.0335e+00,  1.0008e+01,  7.0259e+00,  5.8729e-01,\n",
       "          5.4533e+00,  1.6974e+01,  2.2725e+00,  1.1740e+00,  6.1440e+00,\n",
       "         -6.0599e+00, -6.3021e+00,  7.8884e-01, -8.0896e+00, -4.5481e-01,\n",
       "          3.3872e+00,  9.3435e+00],\n",
       "        [-7.8679e+00, -1.6182e+00, -4.2121e-02,  4.3385e+00, -1.6327e+00,\n",
       "          8.8876e-01, -1.5585e+00, -1.4345e+00,  1.2743e+01,  2.5610e+00,\n",
       "         -4.5769e+00,  4.6652e+00,  6.2459e+00, -3.0036e-01, -2.9372e+00,\n",
       "         -8.4701e+00, -3.6149e+00, -2.3309e+00, -3.5293e+00, -1.0078e+01,\n",
       "         -1.2718e+01, -7.3491e+00,  2.5127e+00,  3.5875e+00,  2.2173e+00,\n",
       "          3.6131e+00,  2.3708e-02],\n",
       "        [ 8.0311e+00,  7.0289e+00,  7.9380e+00, -1.6022e+00, -1.5210e+01,\n",
       "          3.3077e+00, -5.2534e+00, -1.2413e+01, -8.3736e+00,  1.6201e+01,\n",
       "          4.8487e+00,  7.9556e+00, -1.3578e+01,  4.0718e-01, -1.0991e+01,\n",
       "         -3.1116e+00, -1.5448e+01, -3.5630e+00, -3.0139e+00, -6.1959e+00,\n",
       "         -2.6393e+00, -2.3481e+00,  1.0580e+01,  2.5119e+00,  2.8791e+00,\n",
       "         -4.8778e+00, -1.2916e+01],\n",
       "        [ 4.7743e+00,  1.9085e+01,  1.8615e+00, -1.4509e+00, -8.8175e+00,\n",
       "          8.8858e+00, -2.7895e-01, -2.2783e+00,  3.6899e+00,  1.1996e+01,\n",
       "         -3.9083e+00,  2.8185e+00, -7.9697e+00, -2.9562e+00,  1.2423e+00,\n",
       "          1.8585e+00,  8.6392e+00,  7.7459e+00,  9.2110e+00,  1.1006e+01,\n",
       "         -3.0882e-01,  2.7481e+00,  1.0786e+01, -2.1159e+01,  1.3683e+00,\n",
       "          8.3036e+00,  1.1513e+00],\n",
       "        [ 1.6019e+01,  1.0070e+01,  7.9185e+00,  2.6796e+00, -6.6344e+00,\n",
       "          2.3836e+00, -9.6993e+00, -1.3032e+00, -1.4471e+00,  8.6424e+00,\n",
       "         -9.4579e-01, -1.6154e+00,  5.4321e+00,  9.4186e+00,  5.7459e+00,\n",
       "          5.7469e+00,  5.1825e+00, -7.8656e-01, -1.5618e+00,  1.8673e+00,\n",
       "          4.7181e+00,  4.0577e+00,  8.8210e+00, -2.7870e+00, -6.6947e+00,\n",
       "          9.8152e-01,  1.2633e+00]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([13.3347, 17.7906, 20.6013, 20.6118, 16.7355, 13.3347, 15.9986, 14.1725,\n",
       "        15.9149, 18.3614, 15.9397, 20.9265, 13.3347, 17.1088, 17.1319, 20.0600,\n",
       "        13.3347, 16.5889, 15.1016, 17.0579, 18.5863, 15.9671, 10.8740, 10.6872,\n",
       "        15.5056, 13.3347, 16.1793, 16.9743, 12.7427, 16.2007, 19.0847, 16.0194],\n",
       "       grad_fn=<MaxBackward0>),\n",
       "indices=tensor([19, 13, 13,  1,  0, 19, 12,  9, 22,  9,  1,  0, 19, 22,  1,  0, 19, 19,\n",
       "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0]))"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
       "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
